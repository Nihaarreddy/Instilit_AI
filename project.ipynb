{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:43.838128Z",
     "start_time": "2025-07-06T19:34:43.808184Z"
    }
   },
   "source": [
    "# importing all the modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.outliers import Winsorizer\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data_ingestion import fetch_data_sqlalchemy\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import (DataDriftPreset,TargetDriftPreset, DataQualityPreset)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shap"
   ],
   "outputs": [],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:46.213468Z",
     "start_time": "2025-07-06T19:34:44.577408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# connecting to the database\n",
    "df = fetch_data_sqlalchemy(\n",
    "    host='localhost',\n",
    "    port=5432,\n",
    "    database='postgres',\n",
    "    user='postgres',\n",
    "    password='Nihaar6',\n",
    "    table_name='employee_salaries'\n",
    ")\n"
   ],
   "id": "13cc38195790548f",
   "outputs": [],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:46.763508Z",
     "start_time": "2025-07-06T19:34:46.659154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocessing of missing values\n",
    "\n",
    "# 1. Fill missing 'experience_level' with mode\n",
    "df['experience_level'] = df['experience_level'].fillna(df['experience_level'].mode()[0])\n",
    "\n",
    "# 2. Fill missing 'employment_type' with mode\n",
    "df['employment_type'] = df['employment_type'].fillna(df['employment_type'].mode()[0])\n",
    "\n",
    "# 3. Fill missing numerical values (if any) with median\n",
    "num_cols = ['years_experience', 'base_salary', 'bonus', 'stock_options', 'total_salary', 'salary_in_usd', 'conversion_rate', 'adjusted_total_usd']\n",
    "for col in num_cols:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].median())"
   ],
   "id": "5322ddbf2cb5786b",
   "outputs": [],
   "execution_count": 217
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:47.342143Z",
     "start_time": "2025-07-06T19:34:47.270025Z"
    }
   },
   "cell_type": "code",
   "source": "df.isna().sum()",
   "id": "172c15d2ae77eb4d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title             0\n",
       "experience_level      0\n",
       "employment_type       0\n",
       "company_size          0\n",
       "company_location      0\n",
       "remote_ratio          0\n",
       "salary_currency       0\n",
       "years_experience      0\n",
       "base_salary           0\n",
       "bonus                 0\n",
       "stock_options         0\n",
       "total_salary          0\n",
       "salary_in_usd         0\n",
       "currency              0\n",
       "conversion_rate       0\n",
       "adjusted_total_usd    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:47.831143Z",
     "start_time": "2025-07-06T19:34:47.705793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing null values in target\n",
    "# Step 1: Remove 0 or NaN salaries\n",
    "df = df[df['adjusted_total_usd'].notna() & (df['adjusted_total_usd'] > 0)]"
   ],
   "id": "481eae828f27a955",
   "outputs": [],
   "execution_count": 219
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:48.188308Z",
     "start_time": "2025-07-06T19:34:48.158297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing Outliers\n",
    "# Step 2: Clip extreme values (1st and 99th percentiles)\n",
    "low, high = df['adjusted_total_usd'].quantile([0.01, 0.99])\n",
    "df['adjusted_total_usd_clipped'] = df['adjusted_total_usd'].clip(lower=low, upper=high)"
   ],
   "id": "e7f1f674d31a2d6e",
   "outputs": [],
   "execution_count": 220
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:48.611790Z",
     "start_time": "2025-07-06T19:34:48.599284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3: Log-transform\n",
    "df['log_salary'] = np.log1p(df['adjusted_total_usd_clipped'])"
   ],
   "id": "8e2d32d1deb041cc",
   "outputs": [],
   "execution_count": 221
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:49.003458Z",
     "start_time": "2025-07-06T19:34:48.974126Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "8031ba1a5791b208",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            job_title experience_level employment_type company_size  \\\n",
       "0        Data Analyst              Mid        Contract       Medium   \n",
       "1     DevOps Engineer              Mid        Contract        Small   \n",
       "2  Research Scientist             Lead       Part-time       Medium   \n",
       "3       Software Engr             Lead       Full-time        Large   \n",
       "4       Software Engr             Lead          Intern        Large   \n",
       "\n",
       "  company_location  remote_ratio salary_currency  years_experience  \\\n",
       "0          Germany             0             INR              13.0   \n",
       "1            India           100             GBP               9.0   \n",
       "2          Germany             0             EUR              19.0   \n",
       "3            India            50             INR               7.0   \n",
       "4          Germany           100             INR              10.0   \n",
       "\n",
       "    base_salary   bonus  stock_options  total_salary  salary_in_usd currency  \\\n",
       "0   68407.45175  1100.0        19325.0   88832.45175    1065.989421      USD   \n",
       "1   64193.11777  2194.0        19164.0   85551.11777  111216.453100      EUR   \n",
       "2  136071.84290  3206.0        12735.0  152012.84290  167214.127200      EUR   \n",
       "3  141850.90530  9594.0        11158.0  162602.90530   19512.348640      USD   \n",
       "4  121841.16320  6796.0          806.0  129443.16320    1553.317959      INR   \n",
       "\n",
       "   conversion_rate  adjusted_total_usd  adjusted_total_usd_clipped  log_salary  \n",
       "0            1.000        88832.451750                88832.451750   11.394519  \n",
       "1            1.100        94106.229550                94106.229550   11.452190  \n",
       "2            1.100       167214.127200               167214.127200   12.027036  \n",
       "3            1.000       162602.905300               162602.905300   11.999072  \n",
       "4            0.012         1553.317959                 1553.317959    7.348792  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_location</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>base_salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>stock_options</th>\n",
       "      <th>total_salary</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>currency</th>\n",
       "      <th>conversion_rate</th>\n",
       "      <th>adjusted_total_usd</th>\n",
       "      <th>adjusted_total_usd_clipped</th>\n",
       "      <th>log_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>INR</td>\n",
       "      <td>13.0</td>\n",
       "      <td>68407.45175</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>19325.0</td>\n",
       "      <td>88832.45175</td>\n",
       "      <td>1065.989421</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.000</td>\n",
       "      <td>88832.451750</td>\n",
       "      <td>88832.451750</td>\n",
       "      <td>11.394519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Small</td>\n",
       "      <td>India</td>\n",
       "      <td>100</td>\n",
       "      <td>GBP</td>\n",
       "      <td>9.0</td>\n",
       "      <td>64193.11777</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>19164.0</td>\n",
       "      <td>85551.11777</td>\n",
       "      <td>111216.453100</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1.100</td>\n",
       "      <td>94106.229550</td>\n",
       "      <td>94106.229550</td>\n",
       "      <td>11.452190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>19.0</td>\n",
       "      <td>136071.84290</td>\n",
       "      <td>3206.0</td>\n",
       "      <td>12735.0</td>\n",
       "      <td>152012.84290</td>\n",
       "      <td>167214.127200</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1.100</td>\n",
       "      <td>167214.127200</td>\n",
       "      <td>167214.127200</td>\n",
       "      <td>12.027036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Engr</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Large</td>\n",
       "      <td>India</td>\n",
       "      <td>50</td>\n",
       "      <td>INR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>141850.90530</td>\n",
       "      <td>9594.0</td>\n",
       "      <td>11158.0</td>\n",
       "      <td>162602.90530</td>\n",
       "      <td>19512.348640</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.000</td>\n",
       "      <td>162602.905300</td>\n",
       "      <td>162602.905300</td>\n",
       "      <td>11.999072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Software Engr</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Intern</td>\n",
       "      <td>Large</td>\n",
       "      <td>Germany</td>\n",
       "      <td>100</td>\n",
       "      <td>INR</td>\n",
       "      <td>10.0</td>\n",
       "      <td>121841.16320</td>\n",
       "      <td>6796.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>129443.16320</td>\n",
       "      <td>1553.317959</td>\n",
       "      <td>INR</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1553.317959</td>\n",
       "      <td>1553.317959</td>\n",
       "      <td>7.348792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 222
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:49.767908Z",
     "start_time": "2025-07-06T19:34:49.744557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Finding Skewness of target feature\n",
    "df['log_salary'].skew()"
   ],
   "id": "613839e781ece286",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7858337272554825"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 223
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:50.579966Z",
     "start_time": "2025-07-06T19:34:50.410866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target = 'log_salary'\n",
    "X=df[['job_title', 'experience_level', 'employment_type',\n",
    "    'company_size', 'company_location', 'remote_ratio',\n",
    "    'years_experience', 'salary_currency', 'conversion_rate'\n",
    "]]\n",
    "y = df[target]\n"
   ],
   "id": "82652cc909eed404",
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:51.156495Z",
     "start_time": "2025-07-06T19:34:51.139130Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "618d737b0a70a282",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_title', 'experience_level', 'employment_type', 'company_size',\n",
       "       'company_location', 'remote_ratio', 'salary_currency',\n",
       "       'years_experience', 'base_salary', 'bonus', 'stock_options',\n",
       "       'total_salary', 'salary_in_usd', 'currency', 'conversion_rate',\n",
       "       'adjusted_total_usd', 'adjusted_total_usd_clipped', 'log_salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:51.812435Z",
     "start_time": "2025-07-06T19:34:51.760103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# categorizing features into numerical and categorical\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n"
   ],
   "id": "4a78890af4ccd44c",
   "outputs": [],
   "execution_count": 226
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Building Pipelines",
   "id": "4baf76319d91e40b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:53.234243Z",
     "start_time": "2025-07-06T19:34:53.223656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocessing_pipeline(X, pipeline_path = \"preprocess.pkl\"):\n",
    "    numeric_features = X.select_dtypes(include=['number']).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "\n",
    "    winsor = Winsorizer(\n",
    "    capping_method='quantiles',\n",
    "    tail='both',\n",
    "    fold=0.05,\n",
    "    variables=numeric_features\n",
    "    )\n",
    "    df = winsor.fit_transform(X)\n",
    "    numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('winsor',Winsorizer(\n",
    "    capping_method='quantiles',\n",
    "    tail='both',\n",
    "    fold=0.05,\n",
    "\n",
    "    ))\n",
    "    ])\n",
    "    categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output= False))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    "    )\n",
    "    joblib.dump(preprocessor, 'preprocess.pkl')\n",
    "    print(\"✅ Preprocessor saved as 'preprocess.pkl'\")\n",
    "    return preprocessor,numeric_features,categorical_features\n"
   ],
   "id": "8ff987724def2b1e",
   "outputs": [],
   "execution_count": 227
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:54.653515Z",
     "start_time": "2025-07-06T19:34:54.575618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit and transform\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n"
   ],
   "id": "a1c07e0101d8982",
   "outputs": [],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:57.294405Z",
     "start_time": "2025-07-06T19:34:57.283345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get feature names after transformation (for analysis or modeling)\n",
    "def transform_data(df, preprocessor, numeric_features, categorical_features):\n",
    "\n",
    "    processed = preprocessor.fit_transform(df)\n",
    "\n",
    "    cat_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features)\n",
    "    all_feature_names = np.concatenate([numeric_features, cat_feature_names])\n",
    "    return pd.DataFrame(processed,columns=all_feature_names)\n",
    "# print(all_feature_names)\n"
   ],
   "id": "411151773863d878",
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:58.571327Z",
     "start_time": "2025-07-06T19:34:58.459415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Split first\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ],
   "id": "8a9f5bdc44b20287",
   "outputs": [],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:59.742129Z",
     "start_time": "2025-07-06T19:34:59.728076Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "22069d742bf1d410",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:35:01.555224Z",
     "start_time": "2025-07-06T19:35:01.412807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 2. Preprocessing pipeline - fit only on training data\n",
    "preprocessor, numeric_features, categorical_features = preprocessing_pipeline(X_train)"
   ],
   "id": "34edf4a416659bf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessor saved as 'preprocess.pkl'\n"
     ]
    }
   ],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:35:03.055998Z",
     "start_time": "2025-07-06T19:35:02.420886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Transform splits\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ],
   "id": "b2fd0109f8a56d67",
   "outputs": [],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:34:27.422600Z",
     "start_time": "2025-07-06T19:34:27.372213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# If you want feature names:\n",
    "cat_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features)\n",
    "all_feature_names = np.concatenate([numeric_features, cat_feature_names])\n",
    "print(\"All processed feature names:\", all_feature_names)"
   ],
   "id": "6a5cdd719f68c9de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All processed feature names: ['remote_ratio' 'years_experience' 'conversion_rate'\n",
      " 'job_title_Data Analyst' 'job_title_Data Scienist'\n",
      " 'job_title_Data Scntist' 'job_title_DevOps Engineer'\n",
      " 'job_title_Dt Scientist' 'job_title_ML Enginer' 'job_title_ML Engr'\n",
      " 'job_title_Machine Learning Engr' 'job_title_Research Scientist'\n",
      " 'job_title_Software Engr' 'job_title_Softwre Engineer'\n",
      " 'job_title_Sofware Engneer' 'job_title_data analyst'\n",
      " 'experience_level_Junior' 'experience_level_Lead' 'experience_level_Mid'\n",
      " 'experience_level_Senior' 'experience_level_junior'\n",
      " 'experience_level_mid' 'employment_type_Contract'\n",
      " 'employment_type_Full-time' 'employment_type_Intern'\n",
      " 'employment_type_Part-time' 'employment_type_full-time'\n",
      " 'employment_type_part-time' 'company_size_Large' 'company_size_Medium'\n",
      " 'company_size_Small' 'company_size_large' 'company_size_medium'\n",
      " 'company_size_small' 'company_location_Canada' 'company_location_Dubai'\n",
      " 'company_location_Germany' 'company_location_India'\n",
      " 'company_location_Indonesia' 'company_location_Remote'\n",
      " 'company_location_UK' 'company_location_USA' 'salary_currency_12345'\n",
      " 'salary_currency_CAD' 'salary_currency_EUR' 'salary_currency_GBP'\n",
      " 'salary_currency_INR' 'salary_currency_USD']\n"
     ]
    }
   ],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:31:26.300901Z",
     "start_time": "2025-07-06T19:31:25.828681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transforming X\n",
    "processed = transform_data(X, preprocessor, numeric_features, categorical_features)"
   ],
   "id": "40343727866eeb6c",
   "outputs": [],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:31:26.774741Z",
     "start_time": "2025-07-06T19:31:26.768741Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bdfc88965adb21a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:35:20.149362Z",
     "start_time": "2025-07-06T19:35:20.125229Z"
    }
   },
   "cell_type": "code",
   "source": " X_train.columns.tolist()",
   "id": "8c1cb5d0edcdbfe3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job_title',\n",
       " 'experience_level',\n",
       " 'employment_type',\n",
       " 'company_size',\n",
       " 'company_location',\n",
       " 'remote_ratio',\n",
       " 'years_experience',\n",
       " 'salary_currency',\n",
       " 'conversion_rate']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 233
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:35:48.341149Z",
     "start_time": "2025-07-06T19:35:47.686944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fit transforming X_train and X_test\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n"
   ],
   "id": "c63f0cd8e82bc1be",
   "outputs": [],
   "execution_count": 234
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Training\n",
   "id": "905685b5ef98bfff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:35:51.202531Z",
     "start_time": "2025-07-06T19:35:51.183853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "models = {\n",
    "    'LinearRegression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'model': Ridge(),\n",
    "        'params': {'alpha': [0.1, 1.0, 10.0]}\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestRegressor(random_state=42),\n",
    "        'params': {'n_estimators': [100, 200], 'max_depth': [None, 10]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor(random_state=42, verbosity=0),\n",
    "        'params': {'n_estimators': [100, 200], 'max_depth': [3, 6]}\n",
    "    }\n",
    "}\n"
   ],
   "id": "f734a599f6bab8ce",
   "outputs": [],
   "execution_count": 235
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:35:51.838408Z",
     "start_time": "2025-07-06T19:35:51.821284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Avoid division by zero\n",
    "    return np.mean(np.abs((y_true - y_pred) / np.clip(np.abs(y_true), 1e-8, None))) * 100"
   ],
   "id": "e5649452f0bfc567",
   "outputs": [],
   "execution_count": 236
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:35:52.682199Z",
     "start_time": "2025-07-06T19:35:52.663834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 1. Train and evaluate all models (using preprocessed data)\n",
    "def train_and_evaluate_models(models, X_train, y_train, X_test, y_test,preprocessor, save_dir=\"saved_models\",shap_dir=\"shap_outputs\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(shap_dir, exist_ok=True)\n",
    "\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"Instilit Salary Prediction\")\n",
    "\n",
    "    results = []\n",
    "    best_estimators = {}\n",
    "\n",
    "    for name, mp in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        grid = GridSearchCV(mp['model'], mp['params'], cv=3, scoring='r2', n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        y_pred = grid.predict(X_test)\n",
    "\n",
    "        # Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "        metrics = {\n",
    "        \"mae\": mae,\n",
    "        \"rmse\": rmse,\n",
    "        \"r2\": r2,\n",
    "        \"mape\": mape\n",
    "    }\n",
    "\n",
    "        print(\n",
    "            f\"{name} | MAE: {mae:.2f} | RMSE: {rmse:.2f} | R2: {r2:.3f} | MAPE: {mape:.2f}% | Best Params: {grid.best_params_}\")\n",
    "\n",
    "        results.append({\n",
    "            \"model\": name,\n",
    "            \"best_params\": grid.best_params_,\n",
    "            \"mae\": mae,\n",
    "            \"rmse\": rmse,\n",
    "            \"r2\": r2,\n",
    "            \"mape\": mape\n",
    "        })\n",
    "\n",
    "        # Save the best estimator for this model\n",
    "        model_filename = f\"{save_dir}/{name}_best.pkl\"\n",
    "        joblib.dump(grid.best_estimator_, model_filename)\n",
    "        print(f\"Saved {name} model to {model_filename}\")\n",
    "\n",
    "        # Store best estimator in dictionary\n",
    "        best_estimators[name] = grid.best_estimator_\n",
    "\n",
    "        # 🧪 MLflow logging\n",
    "        with mlflow.start_run(run_name=name) as run:\n",
    "            mlflow.log_params(grid.best_params_)\n",
    "            mlflow.log_metrics(metrics)\n",
    "\n",
    "            input_example = X_test.iloc[:3] if hasattr(X_test, \"iloc\") else X_test[:3]\n",
    "            signature = infer_signature(X_test, y_pred)\n",
    "\n",
    "            #mlflow.sklearn.log_model(grid.best_estimator_, \"model\")\n",
    "\n",
    "            mlflow.sklearn.log_model(\n",
    "                grid.best_estimator_,\n",
    "                name=\"model\",  # use 'name' instead of 'artifact_path'\n",
    "                input_example=input_example,\n",
    "                signature=signature\n",
    "                )\n",
    "\n",
    "            # ✅ SHAP Explanation\n",
    "            try:\n",
    "                explainer = shap.Explainer(grid.best_estimator_, X_val)\n",
    "                shap_values = explainer(X_val)\n",
    "\n",
    "                # Plot and save SHAP summary\n",
    "                shap_path = os.path.join(shap_dir, f\"{name}_shap_summary.png\")\n",
    "                plt.figure()\n",
    "                shap.summary_plot(shap_values, X_val, show=False)\n",
    "                plt.savefig(shap_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(shap_path, artifact_path=\"shap_plots\")\n",
    "                print(f\"✅ SHAP saved & logged: {shap_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ SHAP failed for {name}: {e}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\n📊 All Model Validation Metrics:\")\n",
    "    print(results_df[[\"model\", \"mae\", \"rmse\", \"r2\", \"mape\"]].to_string(index=False))\n",
    "\n",
    "\n",
    "    return results_df, best_estimators\n",
    "\n",
    "\n"
   ],
   "id": "fd6483844c1d26de",
   "outputs": [],
   "execution_count": 237
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:35:53.495624Z",
     "start_time": "2025-07-06T19:35:53.484626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 2. Select the overall best model\n",
    "def select_overall_best_model(results_df, best_estimators,X_train_val, y_train_val,preprocessor, metric=\"rmse\"):\n",
    "    # For RMSE, lower is better; for R2, higher is better\n",
    "    ascending = True if metric in [\"mae\", \"rmse\", \"mape\"] else False\n",
    "    # Step 1: Pick best model\n",
    "    best_row = results_df.sort_values(by=metric, ascending=ascending).iloc[0]\n",
    "    best_model_name = best_row[\"model\"]\n",
    "    best_model = best_estimators[best_model_name]\n",
    "\n",
    "    # printing best model\n",
    "    print(f\"\\nOverall Best Model: {best_model_name} | {metric.upper()}: {best_row[metric]:.4f}\")\n",
    "\n",
    "    # Step 2: Retrain on full data\n",
    "    best_model.fit(X_train_val, y_train_val)\n",
    "\n",
    "    return best_model, best_model_name, best_row\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "84d2921cd37d37b5",
   "outputs": [],
   "execution_count": 238
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:35:54.155057Z",
     "start_time": "2025-07-06T19:35:54.128388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# 3. Create, retrain, and save the final pipeline\n",
    "def retrain_and_save_full_pipeline(preprocessor, best_model, X_full, y_full, save_dir, best_model_name):\n",
    "    # Step 1: Build pipeline\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('Model', best_model)\n",
    "    ])\n",
    "    full_pipeline.fit(X_full, y_full)\n",
    "    # Step 2: Save pipeline locally\n",
    "    pipeline_path = os.path.join(save_dir, f\"final_pipeline_{best_model_name}_new_pipeline.pkl\")\n",
    "    joblib.dump(full_pipeline, pipeline_path)\n",
    "    print(f\"✅ Full pipeline saved at: {pipeline_path}\")\n",
    "\n",
    "\n",
    "    # 🧪 Step 5: Log & register to MLflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"Instilit Salary Prediction\")\n",
    "    client = MlflowClient()\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"Final_{best_model_name}\") as run:\n",
    "        run_id = run.info.run_id\n",
    "\n",
    "        mlflow.log_artifact(pipeline_path, artifact_path=\"model\")\n",
    "        print(f\"🔁 Registering model to Model Registry: {best_model_name}\")\n",
    "        model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "        try:\n",
    "            registered_model = mlflow.register_model(\n",
    "                model_uri=model_uri,\n",
    "                name=best_model_name\n",
    "            )\n",
    "        except mlflow.exceptions.MlflowException:\n",
    "            registered_model = client.create_model_version(\n",
    "                name=best_model_name,\n",
    "                source=model_uri,\n",
    "                run_id=run_id\n",
    "            )\n",
    "\n",
    "        # 🏷️ Step 6: Promote to staging\n",
    "        try:\n",
    "            client.transition_model_version_stage(\n",
    "                name=best_model_name,\n",
    "                version=registered_model.version,\n",
    "                stage=\"Staging\",\n",
    "                archive_existing_versions=True\n",
    "            )\n",
    "            print(f\"✅ Model '{best_model_name}' version {registered_model.version} moved to 'Staging'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Transition to 'Staging' failed: {e}\")\n",
    "\n",
    "        print(f\"🏃 View run {best_model_name} at: http://localhost:5000/#/experiments/{run.info.experiment_id}/runs/{run_id}\")\n",
    "\n",
    "    return full_pipeline, best_model_name, pipeline_path"
   ],
   "id": "3dea7547b6b16a46",
   "outputs": [],
   "execution_count": 239
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:35:54.764627Z",
     "start_time": "2025-07-06T19:35:54.742539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Complete workflow function\n",
    "def full_model_workflow(models, preprocessor, X_train, X_test, y_train, y_test, save_dir=\"saved_models\", metric=\"rmse\"):\n",
    "    # (A) Preprocess train and test data for model selection\n",
    "    #X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    #X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    # (B) Train and evaluate all models\n",
    "    results_df, best_estimators = train_and_evaluate_models(\n",
    "        models, X_train, y_train, X_val, y_val,preprocessor)\n",
    "\n",
    "    # (C) Retrain and save the full pipeline on all data\n",
    "    X_full = pd.concat([X_train, X_test], axis=0)\n",
    "    y_full = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "    # (D) Select the overall best model\n",
    "    best_model, best_model_name, best_row = select_overall_best_model(\n",
    "        results_df, best_estimators,X_full, y_full,preprocessor, metric=metric\n",
    "    )\n",
    "\n",
    "\n",
    "    full_pipeline,best_model_name, pipeline_path = retrain_and_save_full_pipeline(\n",
    "        preprocessor, best_model, X_full, y_full, save_dir, best_model_name\n",
    "    )\n",
    "\n",
    "    return full_pipeline, pipeline_path, best_model_name, best_row, results_df"
   ],
   "id": "ea8017006374b884",
   "outputs": [],
   "execution_count": 240
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:36:03.590620Z",
     "start_time": "2025-07-06T19:35:55.394017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "full_pipeline, pipeline_path, best_model_name, best_row, results_df = full_model_workflow(\n",
    "    models, preprocessor, X_train, X_test, y_train, y_test, save_dir=\"saved_models\", metric=\"rmse\"\n",
    ")\n",
    "\n",
    "# Now you can use full_pipeline or load it from disk:\n",
    "\n"
   ],
   "id": "2b1a494dbdf1124d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LinearRegression...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 618, in fit\n    X, y = validate_data(\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Data Analyst'\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 618, in fit\n    X, y = validate_data(\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Machine Learning Engr'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[241], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Example usage:\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m full_pipeline, pipeline_path, best_model_name, best_row, results_df \u001B[38;5;241m=\u001B[39m \u001B[43mfull_model_workflow\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocessor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msaved_models\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrmse\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m      4\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Now you can use full_pipeline or load it from disk:\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[240], line 8\u001B[0m, in \u001B[0;36mfull_model_workflow\u001B[1;34m(models, preprocessor, X_train, X_test, y_train, y_test, save_dir, metric)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfull_model_workflow\u001B[39m(models, preprocessor, X_train, X_test, y_train, y_test, save_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaved_models\u001B[39m\u001B[38;5;124m\"\u001B[39m, metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrmse\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;66;03m# (A) Preprocess train and test data for model selection\u001B[39;00m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m#X_train_processed = preprocessor.fit_transform(X_train)\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m#X_test_processed = preprocessor.transform(X_test)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# (B) Train and evaluate all models\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m     results_df, best_estimators \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_evaluate_models\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpreprocessor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# (C) Retrain and save the full pipeline on all data\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     X_full \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([X_train, X_test], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "Cell \u001B[1;32mIn[237], line 15\u001B[0m, in \u001B[0;36mtrain_and_evaluate_models\u001B[1;34m(models, X_train, y_train, X_test, y_test, preprocessor, save_dir, shap_dir)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mTraining \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     14\u001B[0m grid \u001B[38;5;241m=\u001B[39m GridSearchCV(mp[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m], mp[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m], cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr2\u001B[39m\u001B[38;5;124m'\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 15\u001B[0m \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m grid\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Metrics\u001B[39;00m\n",
      "File \u001B[1;32m~\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\base.py:1363\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1356\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1358\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1359\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1360\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1361\u001B[0m     )\n\u001B[0;32m   1362\u001B[0m ):\n\u001B[1;32m-> 1363\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m   1045\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m   1046\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m   1047\u001B[0m     )\n\u001B[0;32m   1049\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m-> 1051\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1053\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m   1054\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m   1055\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1603\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1604\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1605\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1028\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m   1021\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[0;32m   1022\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1023\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1024\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1025\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[0;32m   1026\u001B[0m     )\n\u001B[1;32m-> 1028\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1030\u001B[0m \u001B[38;5;66;03m# For callable self.scoring, the return type is only know after\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001B[39;00m\n\u001B[0;32m   1032\u001B[0m \u001B[38;5;66;03m# can now be inserted with the correct key. The type checking\u001B[39;00m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001B[39;00m\n\u001B[0;32m   1034\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring):\n",
      "File \u001B[1;32m~\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    499\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    500\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    501\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    502\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    503\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    504\u001B[0m     )\n\u001B[1;32m--> 505\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    507\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    508\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    509\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    510\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    514\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    515\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 618, in fit\n    X, y = validate_data(\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Data Analyst'\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 618, in fit\n    X, y = validate_data(\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\Minfy\\Instilit_Salary_Prediction\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Machine Learning Engr'\n"
     ]
    }
   ],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T18:13:32.833684300Z",
     "start_time": "2025-07-05T18:29:21.422268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaded_pipeline = joblib.load(pipeline_path)\n",
    "predictions = loaded_pipeline.predict(X_test)\n",
    "print(predictions)"
   ],
   "id": "8a439f02c624d78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.90567034 14.09966666  7.49408765 ... 11.97773595 11.25495622\n",
      " 12.22935283]\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:29:39.238396Z",
     "start_time": "2025-07-06T16:29:37.931294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(processed, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "def generate_and_log_drift_reports(X_train, X_val, X_test, output_dir, feature_names=None):\n",
    "    def ensure_df(data, feature_names):\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            return data\n",
    "        return pd.DataFrame(data, columns=feature_names)\n",
    "\n",
    "    X_train = ensure_df(X_train, feature_names)\n",
    "    X_val = ensure_df(X_val, feature_names)\n",
    "    X_test = ensure_df(X_test, feature_names)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    comparisons = [\n",
    "        (\"train_vs_val\", X_train, X_val),\n",
    "        (\"train_vs_test\", X_train, X_test),\n",
    "        (\"val_vs_test\", X_val, X_test)\n",
    "    ]\n",
    "\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "    mlflow.set_experiment(\"Drift\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"multi_split_drift_log\"):\n",
    "        for name, ref, curr in comparisons:\n",
    "            print(f\"🚀 Running drift check: {name}\")\n",
    "            report = Report(metrics=[DataDriftPreset()])\n",
    "            report.run(reference_data=ref, current_data=curr)\n",
    "\n",
    "            html_path = os.path.join(output_dir, f'{name}.html')\n",
    "            json_dict = report.as_dict()\n",
    "\n",
    "            # Save and log HTML\n",
    "            report.save_html(html_path)\n",
    "            mlflow.log_artifact(html_path, artifact_path=\"evidently_html_reports\")\n",
    "\n",
    "            # ✅ Extract and log drift metrics\n",
    "            drift_result = next(\n",
    "                (m[\"result\"] for m in json_dict[\"metrics\"] if m.get(\"metric\") == \"DataDriftTable\"),\n",
    "                None\n",
    "            )\n",
    "            if drift_result:\n",
    "                mlflow.log_metric(f\"{name}_drift_ratio\", round(drift_result[\"share_of_drifted_columns\"], 4))\n",
    "\n",
    "                for feature, vals in drift_result[\"drift_by_columns\"].items():\n",
    "                    score = vals.get(\"drift_score\")\n",
    "                    if score is not None:\n",
    "                        clean_name = feature.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "                        mlflow.log_metric(f\"{name}_{clean_name}\", round(score, 4))\n",
    "\n",
    "            print(f\"✅ Logged drift metrics for {name} to MLflow.\\n\")\n",
    "\n",
    "        print(f\"🎯 All drift reports and metrics logged under run: {mlflow.active_run().info.run_id}\")\n",
    "\n",
    "# Call the function\n",
    "generate_and_log_drift_reports(X_train, X_val, X_test, output_dir='drift_reports', feature_names=preprocessor.get_feature_names_out())\n",
    "\n"
   ],
   "id": "b1cf7ea694242b74",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m X_temp, X_test, y_temp, y_test \u001B[38;5;241m=\u001B[39m train_test_split(\u001B[43mprocessed\u001B[49m, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m      2\u001B[0m X_train, X_val, y_train, y_val \u001B[38;5;241m=\u001B[39m train_test_split(X_temp, y_temp, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.25\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_and_log_drift_reports\u001B[39m(X_train, X_val, X_test, output_dir, feature_names\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n",
      "\u001B[1;31mNameError\u001B[0m: name 'processed' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "95617e8641a0358a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
